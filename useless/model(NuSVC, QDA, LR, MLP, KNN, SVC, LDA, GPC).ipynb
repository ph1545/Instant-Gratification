{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.decomposition import PCA,IncrementalPCA,KernelPCA,FastICA,TruncatedSVD,randomized_svd,NMF\n",
    "#Pretreatment\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler,QuantileTransformer,RobustScaler,PowerTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "#model\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import svm, neighbors, linear_model, neural_network\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import Matern, RationalQuadratic\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 258)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>muggy-smalt-axolotl-pembus</th>\n",
       "      <th>dorky-peach-sheepdog-ordinal</th>\n",
       "      <th>slimy-seashell-cassowary-goose</th>\n",
       "      <th>snazzy-harlequin-chicken-distraction</th>\n",
       "      <th>frumpy-smalt-mau-ordinal</th>\n",
       "      <th>stealthy-beige-pinscher-golden</th>\n",
       "      <th>chummy-cream-tarantula-entropy</th>\n",
       "      <th>hazy-emerald-cuttlefish-unsorted</th>\n",
       "      <th>nerdy-indigo-wolfhound-sorted</th>\n",
       "      <th>...</th>\n",
       "      <th>wheezy-myrtle-mandrill-entropy</th>\n",
       "      <th>wiggy-lilac-lemming-sorted</th>\n",
       "      <th>gloppy-cerise-snail-contributor</th>\n",
       "      <th>woozy-silver-havanese-gaussian</th>\n",
       "      <th>jumpy-thistle-discus-sorted</th>\n",
       "      <th>muggy-turquoise-donkey-important</th>\n",
       "      <th>blurry-buff-hyena-entropy</th>\n",
       "      <th>bluesy-chocolate-kudu-fepid</th>\n",
       "      <th>gamy-white-monster-expert</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4d1b3f7fff691e39bc3bf0bebaf76eab</td>\n",
       "      <td>-0.652685</td>\n",
       "      <td>-0.320448</td>\n",
       "      <td>-0.990136</td>\n",
       "      <td>0.123433</td>\n",
       "      <td>0.872434</td>\n",
       "      <td>-0.976576</td>\n",
       "      <td>0.986943</td>\n",
       "      <td>-0.654385</td>\n",
       "      <td>0.731564</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.751551</td>\n",
       "      <td>2.214634</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.559592</td>\n",
       "      <td>-0.196727</td>\n",
       "      <td>-0.045499</td>\n",
       "      <td>-0.875327</td>\n",
       "      <td>0.949601</td>\n",
       "      <td>0.532729</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98a8077588b7544a04931dad6ba353e9</td>\n",
       "      <td>1.100477</td>\n",
       "      <td>0.146391</td>\n",
       "      <td>0.548201</td>\n",
       "      <td>-0.743063</td>\n",
       "      <td>-0.776455</td>\n",
       "      <td>0.784679</td>\n",
       "      <td>2.884915</td>\n",
       "      <td>4.547408</td>\n",
       "      <td>-1.348984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127049</td>\n",
       "      <td>-0.591817</td>\n",
       "      <td>-0.694301</td>\n",
       "      <td>-0.356082</td>\n",
       "      <td>-0.689719</td>\n",
       "      <td>-0.164489</td>\n",
       "      <td>0.595378</td>\n",
       "      <td>-0.020808</td>\n",
       "      <td>0.527682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ffe5a67090871f16d50d157c8218597e</td>\n",
       "      <td>1.603370</td>\n",
       "      <td>1.622184</td>\n",
       "      <td>-1.537069</td>\n",
       "      <td>-0.232444</td>\n",
       "      <td>-0.123593</td>\n",
       "      <td>1.186707</td>\n",
       "      <td>-0.748651</td>\n",
       "      <td>4.826237</td>\n",
       "      <td>-2.024633</td>\n",
       "      <td>...</td>\n",
       "      <td>1.463451</td>\n",
       "      <td>0.308423</td>\n",
       "      <td>-1.266921</td>\n",
       "      <td>-1.025875</td>\n",
       "      <td>-0.894283</td>\n",
       "      <td>-1.959455</td>\n",
       "      <td>-0.355648</td>\n",
       "      <td>0.903022</td>\n",
       "      <td>1.032162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f2ded623eac31b8dda979e08c1f36d2e</td>\n",
       "      <td>-2.773063</td>\n",
       "      <td>-1.316827</td>\n",
       "      <td>1.019951</td>\n",
       "      <td>-0.155688</td>\n",
       "      <td>0.262493</td>\n",
       "      <td>0.118541</td>\n",
       "      <td>-0.536831</td>\n",
       "      <td>1.759811</td>\n",
       "      <td>1.169555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013601</td>\n",
       "      <td>0.455910</td>\n",
       "      <td>0.700794</td>\n",
       "      <td>-1.073916</td>\n",
       "      <td>-0.359614</td>\n",
       "      <td>0.141195</td>\n",
       "      <td>1.320309</td>\n",
       "      <td>-0.146764</td>\n",
       "      <td>-0.568746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dcb128ab55bbe055bdecc7d6b63774ea</td>\n",
       "      <td>-2.013425</td>\n",
       "      <td>-0.805431</td>\n",
       "      <td>-0.294763</td>\n",
       "      <td>1.629098</td>\n",
       "      <td>-0.013835</td>\n",
       "      <td>0.075623</td>\n",
       "      <td>0.304643</td>\n",
       "      <td>0.027752</td>\n",
       "      <td>-0.959656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279145</td>\n",
       "      <td>0.675924</td>\n",
       "      <td>-0.492643</td>\n",
       "      <td>0.476203</td>\n",
       "      <td>-0.996044</td>\n",
       "      <td>1.399797</td>\n",
       "      <td>-0.157206</td>\n",
       "      <td>0.015506</td>\n",
       "      <td>1.122774</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  muggy-smalt-axolotl-pembus  \\\n",
       "0  4d1b3f7fff691e39bc3bf0bebaf76eab                   -0.652685   \n",
       "1  98a8077588b7544a04931dad6ba353e9                    1.100477   \n",
       "2  ffe5a67090871f16d50d157c8218597e                    1.603370   \n",
       "3  f2ded623eac31b8dda979e08c1f36d2e                   -2.773063   \n",
       "4  dcb128ab55bbe055bdecc7d6b63774ea                   -2.013425   \n",
       "\n",
       "   dorky-peach-sheepdog-ordinal  slimy-seashell-cassowary-goose  \\\n",
       "0                     -0.320448                       -0.990136   \n",
       "1                      0.146391                        0.548201   \n",
       "2                      1.622184                       -1.537069   \n",
       "3                     -1.316827                        1.019951   \n",
       "4                     -0.805431                       -0.294763   \n",
       "\n",
       "   snazzy-harlequin-chicken-distraction  frumpy-smalt-mau-ordinal  \\\n",
       "0                              0.123433                  0.872434   \n",
       "1                             -0.743063                 -0.776455   \n",
       "2                             -0.232444                 -0.123593   \n",
       "3                             -0.155688                  0.262493   \n",
       "4                              1.629098                 -0.013835   \n",
       "\n",
       "   stealthy-beige-pinscher-golden  chummy-cream-tarantula-entropy  \\\n",
       "0                       -0.976576                        0.986943   \n",
       "1                        0.784679                        2.884915   \n",
       "2                        1.186707                       -0.748651   \n",
       "3                        0.118541                       -0.536831   \n",
       "4                        0.075623                        0.304643   \n",
       "\n",
       "   hazy-emerald-cuttlefish-unsorted  nerdy-indigo-wolfhound-sorted   ...    \\\n",
       "0                         -0.654385                       0.731564   ...     \n",
       "1                          4.547408                      -1.348984   ...     \n",
       "2                          4.826237                      -2.024633   ...     \n",
       "3                          1.759811                       1.169555   ...     \n",
       "4                          0.027752                      -0.959656   ...     \n",
       "\n",
       "   wheezy-myrtle-mandrill-entropy  wiggy-lilac-lemming-sorted  \\\n",
       "0                       -0.751551                    2.214634   \n",
       "1                        0.127049                   -0.591817   \n",
       "2                        1.463451                    0.308423   \n",
       "3                       -0.013601                    0.455910   \n",
       "4                        0.279145                    0.675924   \n",
       "\n",
       "   gloppy-cerise-snail-contributor  woozy-silver-havanese-gaussian  \\\n",
       "0                         0.036100                        0.559592   \n",
       "1                        -0.694301                       -0.356082   \n",
       "2                        -1.266921                       -1.025875   \n",
       "3                         0.700794                       -1.073916   \n",
       "4                        -0.492643                        0.476203   \n",
       "\n",
       "   jumpy-thistle-discus-sorted  muggy-turquoise-donkey-important  \\\n",
       "0                    -0.196727                         -0.045499   \n",
       "1                    -0.689719                         -0.164489   \n",
       "2                    -0.894283                         -1.959455   \n",
       "3                    -0.359614                          0.141195   \n",
       "4                    -0.996044                          1.399797   \n",
       "\n",
       "   blurry-buff-hyena-entropy  bluesy-chocolate-kudu-fepid  \\\n",
       "0                  -0.875327                     0.949601   \n",
       "1                   0.595378                    -0.020808   \n",
       "2                  -0.355648                     0.903022   \n",
       "3                   1.320309                    -0.146764   \n",
       "4                  -0.157206                     0.015506   \n",
       "\n",
       "   gamy-white-monster-expert  target  \n",
       "0                   0.532729       1  \n",
       "1                   0.527682       0  \n",
       "2                   1.032162       0  \n",
       "3                  -0.568746       1  \n",
       "4                   1.122774       1  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n",
    "\n",
    "#'wheezy-copper-turtle-magic'가 1인변수만 테스트\n",
    "train1 = train[train['wheezy-copper-turtle-magic']==1]\n",
    "test1 = test[test['wheezy-copper-turtle-magic']==1]\n",
    "train1.reset_index(drop=True,inplace=True)\n",
    "print(train1.shape)\n",
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof1=np.zeros(len(train1))\n",
    "oof2=np.zeros(len(train1))\n",
    "oof3=np.zeros(len(train1))\n",
    "oof4=np.zeros(len(train1))\n",
    "oof5=np.zeros(len(train1))\n",
    "oof6=np.zeros(len(train1))\n",
    "oof7=np.zeros(len(train1))\n",
    "oof8=np.zeros(len(train1))\n",
    "oof9=np.zeros(len(train1))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "vt = VarianceThreshold(threshold=1.5)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "sc = StandardScaler(); rc = RobustScaler()\n",
    "pca = PCA(svd_solver='full',n_components='mle')\n",
    "\n",
    "# VarianceThreshold\n",
    "train2 = vt.fit_transform(train1[cols])\n",
    "# RobustScaler + VarianceThreshold\n",
    "train3 = sc.fit_transform(vt.fit_transform(train1[cols]))\n",
    "# StandardScaler + VarianceThreshold\n",
    "train4 = rc.fit_transform(vt.fit_transform(train1[cols]))\n",
    "# StandardScaler + PCA\n",
    "train5 = sc.fit_transform(pca.fit_transform(train1[cols]))\n",
    "# RobustScaler + PCA\n",
    "train6 = rc.fit_transform(pca.fit_transform(train1[cols]))\n",
    "# PolynomialFeatures + StandardScaler + VarianceThreshold\n",
    "train7 = poly.fit_transform(sc.fit_transform(vt.fit_transform(train1[cols])))\n",
    "# PolynomialFeatures + RobustScaler+ VarianceThreshold\n",
    "train8 = poly.fit_transform(rc.fit_transform(vt.fit_transform(train1[cols])))\n",
    "# StandardScaler + PolynomialFeatures + VarianceThreshold\n",
    "train9 = sc.fit_transform(poly.fit_transform(vt.fit_transform(train1[cols])))\n",
    "# RobustScaler + PolynomialFeatures + VarianceThreshold\n",
    "train10 = rc.fit_transform(poly.fit_transform(vt.fit_transform(train1[cols])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- VarianceThreshold\n",
    "- RobustScaler + VarianceThreshold + model(NuSVC, QDA, LR, MLP, KNN, SVC, LDA, GPC)\n",
    "- StandardScaler + VarianceThreshold + model(NuSVC, QDA, LR, MLP, KNN, SVC, LDA, GPC)\n",
    "- StandardScaler + PCA + model(NuSVC, QDA, LR, MLP, KNN, SVC, LDA, GPC)\n",
    "- RobustScaler + PCA + model(NuSVC, QDA, LR, MLP, KNN, SVC, LDA, GPC)\n",
    "- PolynomialFeatures + StandardScaler + VarianceThreshold + model(NuSVC, QDA, LR, MLP, KNN, SVC, LDA, GPC)\n",
    "- PolynomialFeatures + RobustScaler+ VarianceThreshold + model(NuSVC, QDA, LR, MLP, KNN, SVC, LDA, GPC)\n",
    "- StandardScaler + PolynomialFeatures + VarianceThreshold + model(NuSVC, QDA, LR, MLP, KNN, SVC, LDA, GPC)\n",
    "- RobustScaler + PolynomialFeatures + VarianceThreshold + model(NuSVC, QDA, LR, MLP, KNN, SVC, LDA, GPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUSVC1 auc:  0.93473\n",
      "NUSVC2 auc:  0.94829\n",
      "NUSVC3 auc:  0.948\n",
      "NUSVC4 auc:  0.95185\n",
      "NUSVC5 auc:  0.95261\n",
      "NUSVC6 auc:  0.91602\n",
      "NUSVC7 auc:  0.93979\n",
      "NUSVC8 auc:  0.92372\n",
      "NUSVC9 auc:  0.88953\n"
     ]
    }
   ],
   "source": [
    "idx1 = train1.index\n",
    "for train_index, test_index in skf.split(train2, train1['target']):\n",
    "\n",
    "        clf =NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.59, coef0=0.053)\n",
    "        clf.fit(train2[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof1[idx1[test_index]] = clf.predict_proba(train2[test_index,:])[:,1]\n",
    "        clf.fit(train3[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof2[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "        clf.fit(train4[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof3[idx1[test_index]] = clf.predict_proba(train4[test_index,:])[:,1]\n",
    "        clf.fit(train5[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof4[idx1[test_index]] = clf.predict_proba(train5[test_index,:])[:,1] \n",
    "        clf.fit(train6[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof5[idx1[test_index]] = clf.predict_proba(train6[test_index,:])[:,1] \n",
    "        clf.fit(train7[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof6[idx1[test_index]] = clf.predict_proba(train7[test_index,:])[:,1] \n",
    "        clf.fit(train8[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof7[idx1[test_index]] = clf.predict_proba(train8[test_index,:])[:,1] \n",
    "        clf.fit(train9[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof8[idx1[test_index]] = clf.predict_proba(train9[test_index,:])[:,1] \n",
    "        clf.fit(train10[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof9[idx1[test_index]] = clf.predict_proba(train10[test_index,:])[:,1]         \n",
    "\n",
    "print('NUSVC1 auc: ', round(roc_auc_score(train1['target'], oof1),5))\n",
    "print('NUSVC2 auc: ', round(roc_auc_score(train1['target'], oof2),5))\n",
    "print('NUSVC3 auc: ', round(roc_auc_score(train1['target'], oof3),5))\n",
    "print('NUSVC4 auc: ', round(roc_auc_score(train1['target'], oof4),5))\n",
    "print('NUSVC5 auc: ', round(roc_auc_score(train1['target'], oof5),5))\n",
    "print('NUSVC6 auc: ', round(roc_auc_score(train1['target'], oof6),5))\n",
    "print('NUSVC7 auc: ', round(roc_auc_score(train1['target'], oof7),5))\n",
    "print('NUSVC8 auc: ', round(roc_auc_score(train1['target'], oof8),5))\n",
    "print('NUSVC9 auc: ', round(roc_auc_score(train1['target'], oof9),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QD1 auc:  0.95848\n",
      "QD2 auc:  0.95848\n",
      "QD3 auc:  0.95848\n",
      "QD4 auc:  0.95642\n",
      "QD5 auc:  0.95642\n",
      "QD6 auc:  0.56014\n",
      "QD7 auc:  0.54065\n",
      "QD8 auc:  0.52952\n",
      "QD9 auc:  0.5479\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(train2, train1['target']):\n",
    "\n",
    "        clf =QuadraticDiscriminantAnalysis(0.1)\n",
    "        clf.fit(train2[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof1[idx1[test_index]] = clf.predict_proba(train2[test_index,:])[:,1]\n",
    "        clf.fit(train3[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof2[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "        clf.fit(train4[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof3[idx1[test_index]] = clf.predict_proba(train4[test_index,:])[:,1]\n",
    "        clf.fit(train5[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof4[idx1[test_index]] = clf.predict_proba(train5[test_index,:])[:,1] \n",
    "        clf.fit(train6[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof5[idx1[test_index]] = clf.predict_proba(train6[test_index,:])[:,1] \n",
    "        clf.fit(train7[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof6[idx1[test_index]] = clf.predict_proba(train7[test_index,:])[:,1] \n",
    "        clf.fit(train8[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof7[idx1[test_index]] = clf.predict_proba(train8[test_index,:])[:,1] \n",
    "        clf.fit(train9[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof8[idx1[test_index]] = clf.predict_proba(train9[test_index,:])[:,1] \n",
    "        clf.fit(train10[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof9[idx1[test_index]] = clf.predict_proba(train10[test_index,:])[:,1]         \n",
    "\n",
    "print('QD1 auc: ', round(roc_auc_score(train1['target'], oof1),5))\n",
    "print('QD2 auc: ', round(roc_auc_score(train1['target'], oof2),5))\n",
    "print('QD3 auc: ', round(roc_auc_score(train1['target'], oof3),5))\n",
    "print('QD4 auc: ', round(roc_auc_score(train1['target'], oof4),5))\n",
    "print('QD5 auc: ', round(roc_auc_score(train1['target'], oof5),5))\n",
    "print('QD6 auc: ', round(roc_auc_score(train1['target'], oof6),5))\n",
    "print('QD7 auc: ', round(roc_auc_score(train1['target'], oof7),5))\n",
    "print('QD8 auc: ', round(roc_auc_score(train1['target'], oof8),5))\n",
    "print('QD9 auc: ', round(roc_auc_score(train1['target'], oof9),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR auc:  0.87794\n",
      "LR auc:  0.87762\n",
      "LR auc:  0.87505\n",
      "LR auc:  0.87648\n",
      "LR auc:  0.87646\n",
      "LR auc:  0.94006\n",
      "LR auc:  0.946\n",
      "LR auc:  0.94067\n",
      "LR auc:  0.93157\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(train2, train1['target']):\n",
    "\n",
    "        clf =LogisticRegression(solver='saga',penalty='l2',C=0.01,tol=0.001)\n",
    "        clf.fit(train2[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof1[idx1[test_index]] = clf.predict_proba(train2[test_index,:])[:,1]\n",
    "        clf.fit(train3[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof2[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "        clf.fit(train4[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof3[idx1[test_index]] = clf.predict_proba(train4[test_index,:])[:,1]\n",
    "        clf.fit(train5[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof4[idx1[test_index]] = clf.predict_proba(train5[test_index,:])[:,1] \n",
    "        clf.fit(train6[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof5[idx1[test_index]] = clf.predict_proba(train6[test_index,:])[:,1] \n",
    "        clf.fit(train7[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof6[idx1[test_index]] = clf.predict_proba(train7[test_index,:])[:,1] \n",
    "        clf.fit(train8[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof7[idx1[test_index]] = clf.predict_proba(train8[test_index,:])[:,1] \n",
    "        clf.fit(train9[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof8[idx1[test_index]] = clf.predict_proba(train9[test_index,:])[:,1] \n",
    "        clf.fit(train10[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof9[idx1[test_index]] = clf.predict_proba(train10[test_index,:])[:,1]         \n",
    "\n",
    "print('LR auc: ', round(roc_auc_score(train1['target'], oof1),5))\n",
    "print('LR auc: ', round(roc_auc_score(train1['target'], oof2),5))\n",
    "print('LR auc: ', round(roc_auc_score(train1['target'], oof3),5))\n",
    "print('LR auc: ', round(roc_auc_score(train1['target'], oof4),5))\n",
    "print('LR auc: ', round(roc_auc_score(train1['target'], oof5),5))\n",
    "print('LR auc: ', round(roc_auc_score(train1['target'], oof6),5))\n",
    "print('LR auc: ', round(roc_auc_score(train1['target'], oof7),5))\n",
    "print('LR auc: ', round(roc_auc_score(train1['target'], oof8),5))\n",
    "print('LR auc: ', round(roc_auc_score(train1['target'], oof9),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP1 auc:  0.91981\n",
      "MLP2 auc:  0.91967\n",
      "MLP3 auc:  0.91724\n",
      "MLP4 auc:  0.91693\n",
      "MLP5 auc:  0.91439\n",
      "MLP6 auc:  0.92672\n",
      "MLP7 auc:  0.9312\n",
      "MLP8 auc:  0.93116\n",
      "MLP9 auc:  0.92464\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(train2, train1['target']):\n",
    "\n",
    "        clf =neural_network.MLPClassifier(random_state=3,  activation='relu',solver='adam' )\n",
    "        clf.fit(train2[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof1[idx1[test_index]] = clf.predict_proba(train2[test_index,:])[:,1]\n",
    "        clf.fit(train3[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof2[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "        clf.fit(train4[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof3[idx1[test_index]] = clf.predict_proba(train4[test_index,:])[:,1]\n",
    "        clf.fit(train5[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof4[idx1[test_index]] = clf.predict_proba(train5[test_index,:])[:,1] \n",
    "        clf.fit(train6[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof5[idx1[test_index]] = clf.predict_proba(train6[test_index,:])[:,1] \n",
    "        clf.fit(train7[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof6[idx1[test_index]] = clf.predict_proba(train7[test_index,:])[:,1] \n",
    "        clf.fit(train8[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof7[idx1[test_index]] = clf.predict_proba(train8[test_index,:])[:,1] \n",
    "        clf.fit(train9[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof8[idx1[test_index]] = clf.predict_proba(train9[test_index,:])[:,1] \n",
    "        clf.fit(train10[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof9[idx1[test_index]] = clf.predict_proba(train10[test_index,:])[:,1]         \n",
    "\n",
    "print('MLP1 auc: ', round(roc_auc_score(train1['target'], oof1),5))\n",
    "print('MLP2 auc: ', round(roc_auc_score(train1['target'], oof2),5))\n",
    "print('MLP3 auc: ', round(roc_auc_score(train1['target'], oof3),5))\n",
    "print('MLP4 auc: ', round(roc_auc_score(train1['target'], oof4),5))\n",
    "print('MLP5 auc: ', round(roc_auc_score(train1['target'], oof5),5))\n",
    "print('MLP6 auc: ', round(roc_auc_score(train1['target'], oof6),5))\n",
    "print('MLP7 auc: ', round(roc_auc_score(train1['target'], oof7),5))\n",
    "print('MLP8 auc: ', round(roc_auc_score(train1['target'], oof8),5))\n",
    "print('MLP9 auc: ', round(roc_auc_score(train1['target'], oof9),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN1 auc:  0.93756\n",
      "KNN2 auc:  0.9341\n",
      "KNN3 auc:  0.93343\n",
      "KNN4 auc:  0.93511\n",
      "KNN5 auc:  0.92985\n",
      "KNN6 auc:  0.77233\n",
      "KNN7 auc:  0.81469\n",
      "KNN8 auc:  0.78652\n",
      "KNN9 auc:  0.74774\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(train2, train1['target']):\n",
    "\n",
    "        clf =neighbors.KNeighborsClassifier(n_neighbors=17, p=2.9)\n",
    "        clf.fit(train2[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof1[idx1[test_index]] = clf.predict_proba(train2[test_index,:])[:,1]\n",
    "        clf.fit(train3[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof2[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "        clf.fit(train4[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof3[idx1[test_index]] = clf.predict_proba(train4[test_index,:])[:,1]\n",
    "        clf.fit(train5[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof4[idx1[test_index]] = clf.predict_proba(train5[test_index,:])[:,1] \n",
    "        clf.fit(train6[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof5[idx1[test_index]] = clf.predict_proba(train6[test_index,:])[:,1] \n",
    "        clf.fit(train7[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof6[idx1[test_index]] = clf.predict_proba(train7[test_index,:])[:,1] \n",
    "        clf.fit(train8[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof7[idx1[test_index]] = clf.predict_proba(train8[test_index,:])[:,1] \n",
    "        clf.fit(train9[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof8[idx1[test_index]] = clf.predict_proba(train9[test_index,:])[:,1] \n",
    "        clf.fit(train10[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof9[idx1[test_index]] = clf.predict_proba(train10[test_index,:])[:,1]         \n",
    "\n",
    "print('KNN1 auc: ', round(roc_auc_score(train1['target'], oof1),5))\n",
    "print('KNN2 auc: ', round(roc_auc_score(train1['target'], oof2),5))\n",
    "print('KNN3 auc: ', round(roc_auc_score(train1['target'], oof3),5))\n",
    "print('KNN4 auc: ', round(roc_auc_score(train1['target'], oof4),5))\n",
    "print('KNN5 auc: ', round(roc_auc_score(train1['target'], oof5),5))\n",
    "print('KNN6 auc: ', round(roc_auc_score(train1['target'], oof6),5))\n",
    "print('KNN7 auc: ', round(roc_auc_score(train1['target'], oof7),5))\n",
    "print('KNN8 auc: ', round(roc_auc_score(train1['target'], oof8),5))\n",
    "print('KNN9 auc: ', round(roc_auc_score(train1['target'], oof9),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC1 auc:  0.89894\n",
      "SVC2 auc:  0.91199\n",
      "SVC3 auc:  0.88877\n",
      "SVC4 auc:  0.91922\n",
      "SVC5 auc:  0.86843\n",
      "SVC6 auc:  0.91272\n",
      "SVC7 auc:  0.38114\n",
      "SVC8 auc:  0.8572\n",
      "SVC9 auc:  0.88031\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(train2, train1['target']):\n",
    "\n",
    "        clf =SVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=42)\n",
    "        clf.fit(train2[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof1[idx1[test_index]] = clf.predict_proba(train2[test_index,:])[:,1]\n",
    "        clf.fit(train3[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof2[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "        clf.fit(train4[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof3[idx1[test_index]] = clf.predict_proba(train4[test_index,:])[:,1]\n",
    "        clf.fit(train5[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof4[idx1[test_index]] = clf.predict_proba(train5[test_index,:])[:,1] \n",
    "        clf.fit(train6[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof5[idx1[test_index]] = clf.predict_proba(train6[test_index,:])[:,1] \n",
    "        clf.fit(train7[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof6[idx1[test_index]] = clf.predict_proba(train7[test_index,:])[:,1] \n",
    "        clf.fit(train8[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof7[idx1[test_index]] = clf.predict_proba(train8[test_index,:])[:,1] \n",
    "        clf.fit(train9[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof8[idx1[test_index]] = clf.predict_proba(train9[test_index,:])[:,1] \n",
    "        clf.fit(train10[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof9[idx1[test_index]] = clf.predict_proba(train10[test_index,:])[:,1]         \n",
    "\n",
    "print('SVC1 auc: ', round(roc_auc_score(train1['target'], oof1),5))\n",
    "print('SVC2 auc: ', round(roc_auc_score(train1['target'], oof2),5))\n",
    "print('SVC3 auc: ', round(roc_auc_score(train1['target'], oof3),5))\n",
    "print('SVC4 auc: ', round(roc_auc_score(train1['target'], oof4),5))\n",
    "print('SVC5 auc: ', round(roc_auc_score(train1['target'], oof5),5))\n",
    "print('SVC6 auc: ', round(roc_auc_score(train1['target'], oof6),5))\n",
    "print('SVC7 auc: ', round(roc_auc_score(train1['target'], oof7),5))\n",
    "print('SVC8 auc: ', round(roc_auc_score(train1['target'], oof8),5))\n",
    "print('SVC9 auc: ', round(roc_auc_score(train1['target'], oof9),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA1 auc:  0.87865\n",
      "LDA2 auc:  0.87865\n",
      "LDA3 auc:  0.87865\n",
      "LDA4 auc:  0.87532\n",
      "LDA5 auc:  0.87532\n",
      "LDA6 auc:  0.94364\n",
      "LDA7 auc:  0.94383\n",
      "LDA8 auc:  0.94375\n",
      "LDA9 auc:  0.94375\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(train2, train1['target']):\n",
    "\n",
    "        clf =LinearDiscriminantAnalysis(solver='lsqr',shrinkage='auto')\n",
    "        clf.fit(train2[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof1[idx1[test_index]] = clf.predict_proba(train2[test_index,:])[:,1]\n",
    "        clf.fit(train3[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof2[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "        clf.fit(train4[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof3[idx1[test_index]] = clf.predict_proba(train4[test_index,:])[:,1]\n",
    "        clf.fit(train5[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof4[idx1[test_index]] = clf.predict_proba(train5[test_index,:])[:,1] \n",
    "        clf.fit(train6[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof5[idx1[test_index]] = clf.predict_proba(train6[test_index,:])[:,1] \n",
    "        clf.fit(train7[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof6[idx1[test_index]] = clf.predict_proba(train7[test_index,:])[:,1] \n",
    "        clf.fit(train8[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof7[idx1[test_index]] = clf.predict_proba(train8[test_index,:])[:,1] \n",
    "        clf.fit(train9[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof8[idx1[test_index]] = clf.predict_proba(train9[test_index,:])[:,1] \n",
    "        clf.fit(train10[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof9[idx1[test_index]] = clf.predict_proba(train10[test_index,:])[:,1]         \n",
    "\n",
    "print('LDA1 auc: ', round(roc_auc_score(train1['target'], oof1),5))\n",
    "print('LDA2 auc: ', round(roc_auc_score(train1['target'], oof2),5))\n",
    "print('LDA3 auc: ', round(roc_auc_score(train1['target'], oof3),5))\n",
    "print('LDA4 auc: ', round(roc_auc_score(train1['target'], oof4),5))\n",
    "print('LDA5 auc: ', round(roc_auc_score(train1['target'], oof5),5))\n",
    "print('LDA6 auc: ', round(roc_auc_score(train1['target'], oof6),5))\n",
    "print('LDA7 auc: ', round(roc_auc_score(train1['target'], oof7),5))\n",
    "print('LDA8 auc: ', round(roc_auc_score(train1['target'], oof8),5))\n",
    "print('LDA9 auc: ', round(roc_auc_score(train1['target'], oof9),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPC1 auc:  0.5\n",
      "GPC2 auc:  0.92935\n",
      "GPC3 auc:  0.92883\n",
      "GPC4 auc:  0.90572\n",
      "GPC5 auc:  0.91417\n",
      "GPC6 auc:  0.5\n",
      "GPC7 auc:  0.5\n",
      "GPC8 auc:  0.5\n",
      "GPC9 auc:  0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF\n",
    "for train_index, test_index in skf.split(train2, train1['target']):\n",
    "\n",
    "        clf =GaussianProcessClassifier(2.0 * RBF(1.0))\n",
    "        clf.fit(train2[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof1[idx1[test_index]] = clf.predict_proba(train2[test_index,:])[:,1]\n",
    "        clf.fit(train3[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof2[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "        clf.fit(train4[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof3[idx1[test_index]] = clf.predict_proba(train4[test_index,:])[:,1]\n",
    "        clf.fit(train5[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof4[idx1[test_index]] = clf.predict_proba(train5[test_index,:])[:,1] \n",
    "        clf.fit(train6[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof5[idx1[test_index]] = clf.predict_proba(train6[test_index,:])[:,1] \n",
    "        clf.fit(train7[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof6[idx1[test_index]] = clf.predict_proba(train7[test_index,:])[:,1] \n",
    "        clf.fit(train8[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof7[idx1[test_index]] = clf.predict_proba(train8[test_index,:])[:,1] \n",
    "        clf.fit(train9[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof8[idx1[test_index]] = clf.predict_proba(train9[test_index,:])[:,1] \n",
    "        clf.fit(train10[train_index,:],train1.loc[train_index]['target'])\n",
    "        oof9[idx1[test_index]] = clf.predict_proba(train10[test_index,:])[:,1]         \n",
    "\n",
    "print('GPC1 auc: ', round(roc_auc_score(train1['target'], oof1),5))\n",
    "print('GPC2 auc: ', round(roc_auc_score(train1['target'], oof2),5))\n",
    "print('GPC3 auc: ', round(roc_auc_score(train1['target'], oof3),5))\n",
    "print('GPC4 auc: ', round(roc_auc_score(train1['target'], oof4),5))\n",
    "print('GPC5 auc: ', round(roc_auc_score(train1['target'], oof5),5))\n",
    "print('GPC6 auc: ', round(roc_auc_score(train1['target'], oof6),5))\n",
    "print('GPC7 auc: ', round(roc_auc_score(train1['target'], oof7),5))\n",
    "print('GPC8 auc: ', round(roc_auc_score(train1['target'], oof8),5))\n",
    "print('GPC9 auc: ', round(roc_auc_score(train1['target'], oof9),5))\n",
    "#MultinomialNB, GaussianNB, BernoulliNB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
